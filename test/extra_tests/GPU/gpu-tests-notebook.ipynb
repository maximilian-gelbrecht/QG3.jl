{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for GPU\n",
    "\n",
    "Tests copied from the normal tests to be exectuded in a Jupyter notebook on the HPC by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/p/tmp/maxgelbr/code/qg3.jl/test-cuda`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling QG3 [d558103f-7907-4730-8f30-3d9252e5a318]\n"
     ]
    }
   ],
   "source": [
    "using QG3, CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA runtime 11.4, artifact installation\n",
      "CUDA driver 11.2\n",
      "NVIDIA driver 460.106.0\n",
      "\n",
      "CUDA libraries: \n",
      "- CUBLAS: 11.6.5\n",
      "- CURAND: 10.2.5\n",
      "- CUFFT: 10.5.2\n",
      "- CUSOLVER: 11.2.0\n",
      "- CUSPARSE: 11.6.0\n",
      "- CUPTI: 14.0.0\n",
      "- NVML: 11.0.0+460.106.0\n",
      "\n",
      "Julia packages: \n",
      "- CUDA: 5.0.0\n",
      "- CUDA_Driver_jll: 0.6.0+4\n",
      "- CUDA_Runtime_jll: 0.9.2+3\n",
      "\n",
      "Toolchain:\n",
      "- Julia: 1.9.1\n",
      "- LLVM: 14.0.6\n",
      "- PTX ISA support: 3.2, 4.0, 4.1, 4.2, 4.3, 5.0, 6.0, 6.1, 6.3, 6.4, 6.5, 7.0, 7.1, 7.2\n",
      "- Device capability support: sm_35, sm_37, sm_50, sm_52, sm_53, sm_60, sm_61, sm_62, sm_70, sm_72, sm_75, sm_80, sm_86\n",
      "\n",
      "1 device:\n",
      "  0: Tesla V100-PCIE-32GB (sm_70, 31.745 GiB / 31.749 GiB available)\n"
     ]
    }
   ],
   "source": [
    "CUDA.versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA.CUFFT, Test\n",
    "import FFTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = CUDA.rand(100);\n",
    "W = CUDA.rand(100);\n",
    "V = CUDA.rand(102);\n",
    "\n",
    "Ac = Array(A);\n",
    "\n",
    "A2 = CUDA.rand(10,100);\n",
    "W2 = CUDA.rand(10,100);\n",
    "\n",
    "A3 = CUDA.rand(10,5,100);\n",
    "W3 = CUDA.rand(10,5,100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Differentiable R2R wrapper of CUFFT complex-to-real backward plan for 51-element CuArray of ComplexF32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft_plan = QG3.plan_r2r_AD(A, 1)\n",
    "ifft_plan = QG3.plan_ir2r_AD(fft_plan * A, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Differentiable R2R wrapper of FFTW r2r R2HC plan for 100-element array of Float32\n",
       "(rdft-ct-dit/5\n",
       "  (hc2hc-direct-5/4 \"hf2_5\"\n",
       "    (rdft-r2hc-direct-r2c-5 \"r2cf_5\")\n",
       "    (rdft-r2hc01-direct-r2c-5 \"r2cfII_5\"))\n",
       "  (rdft-r2hc-direct-r2c-20-x5 \"r2cf_20\"))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_fft_plan = QG3.plan_r2r_AD(Ac, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test Array((fft_plan * A)[1:50]) ≈ (cpu_fft_plan * Ac)[1:50] \n",
    "@test Array((fft_plan * A)[53:end-1]) ≈ (cpu_fft_plan * Ac)[end:-1:52] # reverse order in FFTW HC Format\n",
    "@test (fft_plan \\ (fft_plan * A)) ≈ (A * size(A,1))\n",
    "@test ifft_plan * (fft_plan * A) ≈ (A * size(A,1))\n",
    "@test ifft_plan \\ (ifft_plan * (fft_plan * A)) ≈ ((fft_plan * A) * size(A,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifft_plan * (fft_plan * A) ≈ (A * size(A,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic_test_gpu.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load forcing and model parameters\n",
    "\n",
    "    using QG3, BenchmarkTools, OrdinaryDiffEq, JLD2\n",
    "\n",
    "    S, qg3ppars, ψ_0, q_0 = QG3.load_precomputed_data()\n",
    "\n",
    "    QG3.gpuoff()\n",
    "    qg3p_cpu = QG3Model(qg3ppars)\n",
    "    QG3.gpuon()\n",
    "\n",
    "    S_gpu, qg3ppars_gpu, ψ_0_gpu, q_0_gpu = QG3.reorder_SH_gpu(S, qg3ppars), togpu(qg3ppars), QG3.reorder_SH_gpu(ψ_0, qg3ppars), QG3.reorder_SH_gpu(q_0, qg3ppars)\n",
    "\n",
    "    qg3p_gpu = CUDA.@allowscalar QG3Model(qg3ppars_gpu)\n",
    "    T = eltype(qg3p_gpu)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test transform_grid(ψ_0_gpu, qg3p_gpu) ≈ togpu(transform_grid(ψ_0, qg3p_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test QG3.SHtoGrid_dμ(ψ_0_gpu, qg3p_gpu) ≈ togpu(QG3.SHtoGrid_dμ(ψ_0, qg3p_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test QG3.SHtoGrid_dϕ(ψ_0_gpu, qg3p_gpu) ≈ togpu(QG3.SHtoGrid_dϕ(ψ_0, qg3p_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test QG3.SHtoGrid_dλ(ψ_0_gpu, qg3p_gpu) ≈ togpu(QG3.SHtoGrid_dλ(ψ_0, qg3p_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test transform_grid(J(ψ_0_gpu, q_0_gpu, qg3p_gpu),qg3p_gpu) ≈ togpu(transform_grid(J(ψ_0, q_0, qg3p_cpu),qg3p_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = QG3.QG3MM_gpu(q_0_gpu, [qg3p_gpu, S_gpu], 0.)\n",
    "\n",
    "B = QG3.QG3MM_base(q_0, [qg3p_cpu, S], 0.)\n",
    "\n",
    "@test A ≈ QG3.reorder_SH_gpu(B,qg3p_cpu.p)  # time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mUsing arrays or dicts to store parameters of different types can hurt performance.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mConsider using tuples instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SciMLBase ~/.julia/packages/SciMLBase/l4PVV/src/performance_warnings.jl:32\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15.368236 seconds (23.83 M allocations: 1.358 GiB, 5.79% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = T(2π/144)\n",
    "t_end = T(200.)\n",
    "\n",
    "# problem definition with GPU model from the library\n",
    "prob = ODEProblem(QG3.QG3MM_gpu, q_0_gpu, (T(0.),t_end), [qg3p_gpu, S_gpu])\n",
    "\n",
    "sol = @time solve(prob, AB5(), dt=DT)\n",
    "\n",
    "@test SciMLBase.successful_retcode(sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform_fd.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using FiniteDifferences, Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = qg3p_gpu\n",
    "\n",
    "A = ψ_0_gpu\n",
    "Ag = Array(transform_grid(ψ_0_gpu, g))\n",
    "    \n",
    "# first test the r2r plans gradient correctness \n",
    "r2r_plan = QG3.plan_r2r_AD(Ag, 3)\n",
    "Agf = r2r_plan * Ag\n",
    "\n",
    "ir2r_plan = QG3.plan_ir2r_AD(Agf, size(Ag,3), 3)\n",
    "\n",
    "#cpu test\n",
    "y, back = Zygote.pullback(x -> r2r_plan*x, Ag)\n",
    "fd_jvp = j′vp(central_fdm(5,1), x -> r2r_plan*x, y, Ag)\n",
    "diff_val = (fd_jvp[1] - back(y)[1]) \n",
    "@test maximum(abs.(diff_val)) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `r2r_plan_gpu` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `r2r_plan_gpu` not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[12]:2"
     ]
    }
   ],
   "source": [
    "cpudiv = (r2r_plan \\ Agf);\n",
    "gpudiv = (r2r_plan_gpu \\ Agf_gpu);\n",
    "@test cpudiv ≈ Array(gpudiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cpu test 2 \n",
    "yi, backi = Zygote.pullback(x -> ir2r_plan*x, Agf)\n",
    "fd_jvpi = j′vp(central_fdm(5,1), x -> ir2r_plan*x, yi, Agf)\n",
    "diff_val = (fd_jvpi[1] - backi(yi)[1]) \n",
    "@test maximum(abs.(diff_val)) < 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ag_gpu = CUDA.CuArray(Ag)\n",
    "\n",
    "r2r_plan_gpu = QG3.plan_r2r_AD(Ag_gpu, 3)\n",
    "\n",
    "Agf_gpu = r2r_plan_gpu * Ag_gpu\n",
    "ir2r_plan_gpu = QG3.plan_ir2r_AD(Agf_gpu, size(Ag_gpu,3), 3)\n",
    "\n",
    "y_gpu, back_gpu = Zygote.pullback(x -> r2r_plan_gpu*x, Ag_gpu)\n",
    "diff_val = (fd_jvp[1] - Array(back_gpu(y_gpu)[1])) \n",
    "@test maximum(abs.(diff_val)) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpudiv = Array(ir2r_plan_gpu \\ Ag_gpu)\n",
    "cpudiv = ir2r_plan \\ Ag\n",
    "@test gpudiv[:,:,1:33] ≈ cpudiv[:,:,1:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test gpudiv[:,:,35:end-1] ≈ cpudiv[:,:,end:-1:34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gpu, back_gpu = Zygote.pullback(x -> ir2r_plan_gpu*x, Agf_gpu)\n",
    "\n",
    "iback_gpu = back_gpu(y_gpu)[1]; \n",
    "diff_val = Array(iback_gpu[:,:,1:33]) - fd_jvpi[1][:,:,1:33]\n",
    "@test maximum(abs.(diff_val)) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_val = Array(iback_gpu[:,:,35:end-1]) - fd_jvpi[1][:,:,end:-1:34]\n",
    "@test maximum(abs.(diff_val)) < 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "AG = transform_grid(ψ_0_gpu, qg3p_gpu);\n",
    "AG_cpu = Array(AG);\n",
    "\n",
    "AS = ψ_0_gpu;\n",
    "AS_cpu = transform_SH(AG_cpu, qg3p_cpu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cpu, back_cpu = Zygote.pullback(x -> transform_grid(x, qg3p_cpu), AS_cpu)\n",
    "fd_jvp_cpu = j′vp(central_fdm(5,1), x -> transform_grid(x, qg3p_cpu), y_cpu, AS_cpu)\n",
    "diff = (fd_jvp_cpu[1] - back_cpu(y_cpu)[1])\n",
    "@test maximum(abs.(diff)) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gpu, back_gpu = Zygote.pullback(x -> transform_grid(x, qg3p_gpu), AS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test maximum(Array(back_gpu(y_gpu)[1])[:,1:22,1:22] - back_cpu(y_cpu)[1][:,1:22,1:2:end]) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test maximum(back_cpu(y_cpu)[1][:,1:22,2:2:end] - Array(back_gpu(y_gpu)[1])[:,1:22,35:55]) < 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cpu, back_cpu = Zygote.pullback(x -> transform_SH(x, qg3p_cpu), AG_cpu)\n",
    "fd_jvp_cpu = j′vp(central_fdm(5,1), x -> transform_SH(x, qg3p_cpu), y_cpu, AG_cpu)\n",
    "diff = (fd_jvp_cpu[1] - back_cpu(y_cpu)[1])\n",
    "@test maximum(abs.(diff)) < 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gpu, back_gpu = Zygote.pullback(x -> transform_SH(x, qg3p_gpu), AG);\n",
    "@test Array(back_gpu(y_gpu)[1]) ≈ back_cpu(y_cpu)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpu_cpu_compare.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53.396992 seconds (36.74 M allocations: 2.193 GiB, 2.89% gc time)\n",
      " 48.962139 seconds (29.50 M allocations: 1.695 GiB, 2.83% gc time)\n"
     ]
    }
   ],
   "source": [
    " # or use the function that automatically loads the files that are saved in the repository\n",
    "    S, qg3ppars, ψ_0, q_0 = QG3.load_precomputed_data()\n",
    "\n",
    "    # the precomputed fields are loaded on the CPU and are in the wrong SH coefficient convention\n",
    "    S_gpu, qg3ppars_gpu, ψ_0_gpu, q_0_gpu = QG3.reorder_SH_gpu(S, qg3ppars), togpu(qg3ppars), QG3.reorder_SH_gpu(ψ_0, qg3ppars), QG3.reorder_SH_gpu(q_0, qg3ppars)\n",
    "\n",
    "    QG3.gpuoff()\n",
    "    qg3p = CUDA.@allowscalar QG3Model(qg3ppars);\n",
    "    QG3.gpuon()\n",
    "    qg3p_gpu = CUDA.@allowscalar QG3Model(qg3ppars_gpu);\n",
    "\n",
    "    @test QG3.isongpu(qg3p_gpu)\n",
    "    @test !(QG3.isongpu(qg3p))\n",
    "\n",
    "    T = eltype(qg3p_gpu)\n",
    "\n",
    "    a = similar(ψ_0)\n",
    "    a .= 1\n",
    "\n",
    "    a_gpu = similar(ψ_0_gpu)\n",
    "    a_gpu .= 1\n",
    "\n",
    "    function QG3MM_gpu(q)\n",
    "        ψ = qprimetoψ(qg3p_gpu, q)\n",
    "        return - a_gpu .* J(ψ, q, qg3p_gpu) - D(ψ, q, qg3p_gpu) + S_gpu\n",
    "    end\n",
    "\n",
    "    function QG3MM_cpu(q)\n",
    "        ψ = qprimetoψ(qg3p, q)\n",
    "        return - a .* J(ψ, q, qg3p) - D(ψ, q, qg3p) + S\n",
    "    end\n",
    "\n",
    "    g2 = @time gradient(Params([a_gpu])) do\n",
    "        sum(QG3MM_gpu(q_0_gpu))\n",
    "    end\n",
    "    A = g2[a_gpu]\n",
    "\n",
    "    g = @time gradient(Params([a])) do\n",
    "        sum(QG3MM_cpu(q_0))\n",
    "    end\n",
    "    B = g[a];\n",
    "\n",
    "    B_gpu = QG3.reorder_SH_gpu(B, qg3ppars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test A ≈ B_gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mUsing arrays or dicts to store parameters of different types can hurt performance.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mConsider using tuples instead.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SciMLBase ~/.julia/packages/SciMLBase/l4PVV/src/performance_warnings.jl:32\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11.599203 seconds (14.96 M allocations: 1020.406 MiB, 7.87% gc time)\n",
      "  3.968224 seconds (6.20 M allocations: 501.229 MiB, 9.20% gc time)\n",
      "\u001b[91m\u001b[1mTest Failed\u001b[22m\u001b[39m at \u001b[39m\u001b[1mIn[74]:16\u001b[22m\n",
      "  Expression: maximum(diff) < 1.0e-8\n",
      "   Evaluated: 0.00036528337f0 < 1.0e-8\n",
      "\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mThere was an error during testing\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mThere was an error during testing\u001b[39m",
      "",
      "Stacktrace:",
      " [1] record(ts::Test.FallbackTestSet, t::Union{Test.Error, Test.Fail})",
      "   @ Test /p/system/packages/julia/1.9.1/share/julia/stdlib/v1.9/Test/src/Test.jl:960",
      " [2] do_test(result::Test.ExecutionResult, orig_expr::Any)",
      "   @ Test /p/system/packages/julia/1.9.1/share/julia/stdlib/v1.9/Test/src/Test.jl:670",
      " [3] top-level scope",
      "   @ /p/system/packages/julia/1.9.1/share/julia/stdlib/v1.9/Test/src/Test.jl:478"
     ]
    }
   ],
   "source": [
    "RELTOL = 1e-5\n",
    "    RELTOL_PREDICT = 1e-3\n",
    "\n",
    "    DT = T((2π/144) / 10) # in MM code: 1/144 * 2π\n",
    "    t_end = T(100.5)\n",
    "\n",
    "    prob_gpu = ODEProblem(QG3.QG3MM_gpu,q_0_gpu,(T(100.),t_end),[qg3p_gpu, S_gpu])\n",
    "    sol_gpu = @time solve(prob_gpu, Tsit5(), dt=DT, reltol=RELTOL);\n",
    "\n",
    "    prob = ODEProblem(QG3.QG3MM_gpu,q_0,(T(100.),t_end),[qg3p, S])\n",
    "    sol = @time solve(prob, Tsit5(), dt=DT, reltol=RELTOL);\n",
    "\n",
    "    diff = abs.(QG3.reorder_SH_gpu(sol(t_end),qg3ppars) - sol_gpu(t_end))./sol_gpu(t_end)\n",
    "    diff[isnan.(diff)] .= 0;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@test maximum(diff) < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(abs.(diff)) < 1e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
